{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb758f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CAO Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2863c-eb9d-4535-8083-78d7019b084f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The CAO points data, available from the [CAO website](http://www.cao.ie), is published in a different format for each of the years 2019, 2020, and 2021. Each year's data, therefore, requires a different approach to acquisition, conversion to pandas DataFrame, and cleaning. The 2019 data is published in two PDF files; one for level 8 courses, and one for levels 6 and 7. The 2020 data is published as an Excel spreadsheet, and the 2021 data as preformatted text in a HTML web page.\n",
    "\n",
    "The attributes of interest for comparison between the various years' datasets are `Course Code`, `Course Name`, `Institution Name`, `EOS`, which is the number of points achieved by the last applicant to be offered a place on the course, and `Mid`, which is the mid point between the number of points held by the highest point score and the lowest point score of the applicants offered a place on the course [1]. The 2021 data does not explicitly contain an either an `EOS` or a `Mid` column. It does provide the *Round 1* and *Round 2* points required for entry into each course as `RND1` and `RND2`. Examination of the 2020 data, which contains both an `EOS` field *and* `RND1` and `RND2` fields demonstrates that the `EOS` field is equal to the `RND2` value if it exists, otherwise the `RND1` value (```EOS = RND1 if RND1 else RND2```). As for the `Mid` field; this information does not appear to be available yet for the 2021 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e8574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Data analysis library\n",
    "import pandas as pd\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# PDF table parsing\n",
    "from tabula import read_pdf\n",
    "# Retrieval of resources from WWW\n",
    "import requests\n",
    "# URL construction\n",
    "from requests.compat import urljoin\n",
    "# Various utilities, mainly path construction\n",
    "import os\n",
    "# Creation of datetime strings for filenames\n",
    "from datetime import datetime\n",
    "# Regular expressions\n",
    "import re\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from itertools import zip_longest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4508744",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Acquiring the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d548e7b8-1276-48fb-8df4-24e9f107fc99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e93f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of CAO points data\n",
    "base_url = 'http://www2.cao.ie/points/'\n",
    "# Local data directory\n",
    "data_dir = 'data/cao'\n",
    "backup_dir = 'data/cao/backup'\n",
    "\n",
    "# Dictionary of source file names mapped to the file names that will be used locally\n",
    "points_urls  = ({'l8.php'                  : 'cao_2021_lvl8.html',\n",
    "                 'l76.php'                 : 'cao_2021_lvl76.html',\n",
    "                 'CAOPointsCharts2020.xlsx': 'cao_2020_lvl876.xlsx'\n",
    "                 })\n",
    "\n",
    "# The rest of points_urls can be assembled programmatically\n",
    "# as filenames follow a pattern\n",
    "\n",
    "# List of years as 2-digit strings from 2019 to 2005\n",
    "years = [str(i).zfill(2) for i in range(19, 4, -1)]\n",
    "# For each year (2019 to 2005)\n",
    "for year in years:\n",
    "    levels = ('lvl8', 'lvl76')\n",
    "    # Using a separate local_levels variable allows consistent local \n",
    "    # file naming in cases where the remote files are inconsistently named\n",
    "    local_levels = levels\n",
    "    \n",
    "    # 2011 and 2012 data is missing second 'l' from filenames\n",
    "    if year in ('12', '11'):\n",
    "        levels = ('lv8', 'lv76')\n",
    "        \n",
    "    # For each level \n",
    "    for level, local_level in zip(levels, local_levels):\n",
    "        # construct remote filename\n",
    "        remote_name = level + '_' + year + '.pdf'\n",
    "\n",
    "        # construct local filename\n",
    "        local_name = 'cao_20' + year + '_' + local_level + '.pdf'\n",
    "        # Add remote and local filenames as keys and values in points_urls dict\n",
    "        points_urls[remote_name] = local_name\n",
    "\n",
    "# List of years as 2-digit strings from 2004 to 2001\n",
    "years = [str(i).zfill(2) for i in range(4, 0, -1)]\n",
    "for year in years:\n",
    "    levels = ('deg', 'dip')\n",
    "    local_levels = ('lvl8', 'lvl76')\n",
    "\n",
    "    for level, local_level in zip(levels, local_levels):\n",
    "        remote_name = level + year + '.htm'\n",
    "        local_name = 'cao_20' + year + '_' + local_level + '.html'\n",
    "        points_urls[remote_name] = local_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cao_source_data(base_url, points_urls, data_dir, backup_dir, verbose=False):\n",
    "    # for each of the source files \n",
    "    for url in (points_urls):\n",
    "        # construct url and fetch content\n",
    "        response = requests.get(urljoin(base_url, url))\n",
    "\n",
    "        try:\n",
    "            # attempt to open any previously downloaded local file\n",
    "            with open(os.path.join(data_dir, points_urls[url]), \"rb\") as f:\n",
    "                # Calculate md5 hashes for the local file and the remote file\n",
    "                md5_local = hashlib.md5(f.read()).hexdigest()\n",
    "                md5_response = hashlib.md5(response.content).hexdigest()\n",
    "\n",
    "                # Set write_flag to False if the hashes are equal and True if they are not\n",
    "                write_flag = (md5_local != md5_response)\n",
    "        except FileNotFoundError:\n",
    "            # if the local file does not exist set the write_flag to True and move on\n",
    "            write_flag = True\n",
    "\n",
    "        # If the write_flag is True\n",
    "        if write_flag:\n",
    "            if verbose:\n",
    "                print(f\"File: {points_urls[url]} has changed since last download. Updating...\")\n",
    "            # split the filename into name and extension\n",
    "            fname, extension = os.path.splitext(points_urls[url])\n",
    "            # construct unique filename by inserting datetime string between filename and extension\n",
    "            filename = fname + datetime.now().strftime(\"_%Y%m%d_%H%M%S\") + extension\n",
    "\n",
    "            # write the timestamped remote file to the backup directory\n",
    "            with open(os.path.join(backup_dir, filename), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # also write the remote file to the data directory, overwriting any previous file\n",
    "            with open(os.path.join(data_dir, points_urls[url]), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"File: {points_urls[url]} has not changed since last download. Skipping...\")\n",
    "                \n",
    "get_cao_source_data(base_url=base_url, \n",
    "                    points_urls=points_urls, \n",
    "                    data_dir=data_dir, \n",
    "                    backup_dir=backup_dir, \n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a8fca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data supplied as preformatted text embedded in a HTML page\n",
    "#### 2021, 2004, 2003, 2002, and 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba64827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_html(l8, l76, \n",
    "                  columns=['Course Code', 'Course Name', 'EOS', 'Mid', 'Level', 'Institution'], \n",
    "                  name_len=50,\n",
    "                  special=['EOS', 'Mid']):\n",
    "    # Regular expression to capture fields from lines\n",
    "    # Lines consist of 2 letters and 3 numbers, comprising the course code; some whitespace; \n",
    "    # 50 characters which start with a non-whitespace character; some more whitespace;\n",
    "    # some optional non whitespace characters comprising round 1 points; some more whitespace;\n",
    "    # and, optionally some more non-whitespace characters comprising round 2 points if present\n",
    "    re_fields = re.compile(f'^([A-Z]{{2}}[0-9]{{3}})\\s+(\\S.{{{name_len-1}}})\\s+(\\S+)?\\s+(\\S+)?')\n",
    "    re_institution = re.compile(r'^\\s{7}(\\S.+\\S)\\s+$')\n",
    "\n",
    "    # array to hold matched groups\n",
    "    data = []\n",
    "    institution = ''\n",
    "    for datafile, level in zip((l8, l76), (8, 76)):\n",
    "        # encoding=cp1252 necessary to decode some characters on page\n",
    "        with open(datafile, 'r', encoding='cp1252') as f:\n",
    "            for line in f:\n",
    "                match_course = re.match(re_fields, line)\n",
    "                match_institution = re.match(re_institution, line)\n",
    "                if match_institution:\n",
    "                    institution = match_institution.group(0).strip()\n",
    "                if match_course:\n",
    "                    fields = list(match_course.groups())\n",
    "                    fields.append(level)\n",
    "                    fields.append(institution)\n",
    "                    data.append(fields)\n",
    "\n",
    "                    \n",
    "\n",
    "    # column names\n",
    "    #columns = ['Course Code', 'Course Name', 'Rnd1', 'Rnd2', 'Level']\n",
    "    df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "    newcols = {'Test': '#', 'Not All': '\\*', 'AQA': 'AQA', 'New Comp': 'v'}\n",
    "\n",
    "    for k, v in newcols.items():\n",
    "        df[k] = df[special[0]].str.contains(v, na=False) | df[special[1]].str.contains(v, na=False)\n",
    "\n",
    "    # Generate 'EOS' column. == Rnd2 if it exists, otherwise Rnd1\n",
    "    # Only here for 2021 data\n",
    "    if special[0] == 'Rnd1':\n",
    "        df['EOS'] = np.where(df['Rnd2'].isnull(), df['Rnd1'], df['Rnd2'])\n",
    "\n",
    "    # Remove Non-digits from Rnd1 and Rnd2 columns and convert columns to numeric values, \n",
    "    # with NaNs where values are missing (errors = 'coerce')\n",
    "    # (Because NaN is a float, the whole columns must be floats)\n",
    "    df['EOS'] = pd.to_numeric(df['EOS'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "    if 'Mid' in df.columns:\n",
    "        df['Mid'] = pd.to_numeric(df['Mid'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "    else:\n",
    "        df['Mid'] = np.nan\n",
    "\n",
    "    # Use boolean 'Level8' to store level\n",
    "    df['Level8'] = df['Level'] == 8\n",
    "\n",
    "    # Remove unwanted columns and make column orders consistent across years\n",
    "    df = df[['Course Code', 'Course Name', 'Institution', 'EOS', 'Mid', 'Level8', 'Test', 'Not All', 'AQA', 'New Comp']]\n",
    "   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedff052",
   "metadata": {},
   "source": [
    "Create new columns to hold information currently designated by *'s and #'s in numeric columns\n",
    "\n",
    "Create new column indicating whether the course requires a test, interview or portfolio\n",
    "This is indicated by a '#' in the Rnd1 or Rnd2 column\n",
    "df['Test'] = df['Rnd1'].str.contains('#', na=False) | df['Rnd2'].str.contains('#', na=False)\n",
    "\n",
    "Create a column indicating courses where not all applicants at Rnd1 point score were offered a place\n",
    "This is indicated by a '*' in the Rnd1 or Rnd2 column\n",
    "df['Not All'] = df['Rnd1'].str.contains('\\*', na=False) | df['Rnd2'].str.contains('\\*', na=False)\n",
    "\n",
    "Create a new column for AQA meaning All Qualified Applicants were offered a place\n",
    "df['AQA'] = df['Rnd1'].str.contains('AQA', na=False) | df['Rnd2'].str.contains('AQA', na=False)\n",
    "\n",
    "Create a new column for 'New competition for available places' which seems to be courses \n",
    "for which the points have increased in round 2. Only occurs in level 76 and is indicated \n",
    "by a 'v' in 'Rnd2' column\n",
    "df['New Comp'] = df['Rnd1'].str.contains('v', na=False) | df['Rnd2'].str.contains('v', na=False)\n",
    "\n",
    "Generate 'EOS' column. == Rnd2 if it exists, otherwise Rnd1\n",
    "df['EOS'] = np.where(df['Rnd2'].isnull(), df['Rnd1'], df['Rnd2'])\n",
    "\n",
    "Remove Non-digits from Rnd1 and Rnd2 columns and convert columns to numeric values, \n",
    "with NaNs where values are missing (errors = 'coerce')\n",
    "(Because NaN is a float, the whole columns must be floats)\n",
    "df['Rnd1'] = pd.to_numeric(df['Rnd1'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "df['Rnd2'] = pd.to_numeric(df['Rnd2'].str.replace('[^0-9]+', '', regex=True), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f1a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default parameters for read_cao_html() for each year\n",
    "html_files = {2021:{'columns': ['Course Code', 'Course Name', 'Rnd1', 'Rnd2', 'Level','Institution'], \n",
    "                    'special': ['Rnd1', 'Rnd2']},\n",
    "              2004:{},\n",
    "              2003:{},\n",
    "              2002:{},\n",
    "              2001:{'name_len': 35}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ddaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_htmls(html_files):\n",
    "    \"\"\"\n",
    "    Reads in all the html files in the html_files dictionary and returns a dictionary\n",
    "    of dataframes with the year as the key\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    for year, params in html_files.items():\n",
    "        l8 = os.path.join(data_dir, f'cao_{year}_lvl8.html')\n",
    "        l76 = os.path.join(data_dir, f'cao_{year}_lvl76.html') \n",
    "        dfs[year] = read_cao_html(l8, l76, **params)\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e10452",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "### Data supplied as an Excel spreadsheet\n",
    "#### 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15978aa3",
   "metadata": {},
   "source": [
    "1. Read Excel file using pandas.read_excel, specifying header row, desired columns, and row names\n",
    "2. Create and populate 'Test', 'Not All', 'Matric', and 'AQA' columns\n",
    "3. Remove all non-numeric characters from 'EOS' and 'Mid' and convert to numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d8aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_cols(df):\n",
    "    \n",
    "    cols = ['Test', 'Not All', 'Matric', 'AQA', 'New Comp']\n",
    "    markers = ['#', '*', 'mat', 'AQA', 'v']\n",
    "\n",
    "    for col, marker in zip(cols, markers):\n",
    "        df[col] = df['EOS'].str.replace('\\s', '', regex=True).str.contains(marker, na=False, regex=False)\n",
    "\n",
    "    for col in ('EOS', 'Mid'):\n",
    "        # Cast each point col to string so they can be cleaned up using string methods\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "        # Some pdfs have second point values in parentheses \n",
    "        # indicating new competition for additional places which must be removed\n",
    "        # or the two point values will be concatenated in the next step\n",
    "        df[col] = df[col].str.replace('\\(.+\\)', '', regex=True)\n",
    "        \n",
    "        # Remove non digits and decimal points outside numbers\n",
    "        df[col] = df[col].str.replace('[^0-9.]', '', regex=True).str.strip(\".\")\n",
    "\n",
    "        # Cast points columns to float\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce', downcast='float')  \n",
    "            \n",
    "    # Reset the index\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Make column orders consistent across years\n",
    "    df = df[['Course Code', 'Course Name', 'Institution', 'EOS', 'Mid', 'Level8', 'Test', 'Not All', 'AQA', 'New Comp']]\n",
    "           \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6471e278-94a6-4bc3-96b1-c8c1d9e13683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_excel():\n",
    "    \"\"\"\n",
    "    Reads in the CAO excel file and returns a dataframe.\n",
    "    As this is a one-use function all the parameters are hardcoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in the excel file\n",
    "    df = pd.read_excel(os.path.join(data_dir, 'cao_2020_lvl876.xlsx'), \n",
    "                       header=10, \n",
    "                       usecols=\"B,C,H,I,J,K,L\", \n",
    "                       names=['Course Name', 'Course Code', 'EOS', 'EOS *', 'Mid', 'Level8', 'Institution'],\n",
    "                       converters={'EOS':str,'Mid':str})\n",
    "\n",
    "    # Asterisks usually found in EOS are in a separate col in this dataset\n",
    "    # Move asterisks to EOS so generic parser can be used\n",
    "    df['EOS'] = np.where(df['EOS *'].str.contains('*', na=False, regex=False), \n",
    "        df['EOS'] + '*', df['EOS']) \n",
    "    df = df.drop('EOS *', axis=1)\n",
    "\n",
    "    # Change 'Level8' to boolean\n",
    "    df['Level8'] = df['Level8'] == 8\n",
    "\n",
    "    df = tidy_cols(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20791673",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data held as a one-column-per-page table in a PDF file\n",
    "#### 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, and 2005\n",
    "\n",
    "The 2019 points data is held in two PDF files, one for level 8 courses and one for levels 6 and 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861b0a7",
   "metadata": {},
   "source": [
    "1. Read using tabula.read_pdf()\n",
    "2. If necessary remove unwanted rows and assign header row\n",
    "3. Fix and rename headers\n",
    "4. Fill in institution column\n",
    "5. Remove rows without course codes\n",
    "6. Create and populate 'Test', 'Not All', 'Matric', and 'AQA' columns\n",
    "7. Remove all non-numeric characters from 'EOS' and 'Mid' and convert to numeric type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a8b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_pdf(pdf_path, header_row=None, splitfirst=False, table_num=0, drop_col=None, merge_drop=None, multiple_tables=False):\n",
    "    \n",
    "    # Extract level from path\n",
    "    level = re.search('lvl(.+)\\.', pdf_path).group(1)\n",
    "    df = read_pdf(pdf_path, pages='all', multiple_tables=multiple_tables)[table_num]\n",
    "\n",
    "    # 2016 data has a ghost column\n",
    "    if drop_col is not None:\n",
    "        if merge_drop is not None:\n",
    "            col1 = df.columns[drop_col[0]]\n",
    "            col2 = df.columns[merge_drop]\n",
    "            df.loc[df[col2].isnull(), col2] = df[col1]\n",
    "            \n",
    "        df.drop(df.columns[drop_col], axis=1, inplace=True)\n",
    "    \n",
    "    df.columns = ['Course Code', 'Course Name', 'EOS', 'Mid']\n",
    "\n",
    "    if header_row is not None:\n",
    "        # df.columns = df.iloc[header_row]\n",
    "        df.rename_axis(None, axis=1, inplace=True)\n",
    "        \n",
    "        # Delete rows up to header_row\n",
    "        df.drop(df.index[range(0, header_row + 1)], axis=0, inplace=True)\n",
    "        \n",
    "    # A missing vertical line causes some the pdf parser to merge rows \n",
    "    # in certain tables (e.g. 2014 levels 6 & 7)\n",
    "    # If that is the case we need to shift column contents to the right \n",
    "    # then split the first column into course code and course name\n",
    "    if splitfirst:\n",
    "        # Create insititution column and add contents of Course Name column where Course Code is empty\n",
    "        df['Institution'] = df[df['Course Code'].isnull()]['Course Name']\n",
    "        # Shift the values in EOS to Mid\n",
    "        df['Mid'] = df['EOS']\n",
    "        # Shift the values in Course Name to EOS\n",
    "        df['EOS'] = df['Course Name']\n",
    "        # Locate rows with institution names (In Course code col) and move them to Institution col\n",
    "        # Skip the first row because its a unique situation dealt with in the first libne of this if block\n",
    "        df.loc[df.index[1:], 'Institution'] = df[~df['Course Code'].str.contains('[A-Z]{2}\\d{3}', na=False)]['Course Code'] \n",
    "        # Extract the course name from the course code column and place in Course Name column\n",
    "        df['Course Name'] = df['Course Code'].str.extract('^\\D\\D\\d{3}(.+)$')\n",
    "        # Extract the course code form the Course Code column and place in Course Code column\n",
    "        df['Course Code'] = df['Course Code'].str.extract('^(\\D\\D\\d{3})')       \n",
    "    else:\n",
    "        # Create a new column in the dataframe for institution name \n",
    "        # identify institution name rows as those containing null course codes\n",
    "        # and add those institution names to the new institution column\n",
    "        df['Institution'] = df[df['Course Code'].isnull()]['Course Name']\n",
    "        #df.rename(columns={'INSTITUTION and COURSE':'Course Name'}, inplace=True)\n",
    "    \n",
    "    # Fill empty fields in the institution column with the most recent non-na field\n",
    "    df['Institution'] = df['Institution'].fillna(method='ffill')\n",
    "    \n",
    "    # Remove rows containing only institution names\n",
    "    df = df[df['Course Code'].notna()]\n",
    "        \n",
    "    # Remove page header rows\n",
    "    df = df[df['Course Code'] != 'Course Code']\n",
    "    \n",
    "    # Remove oddball rows like two subject modratorships with point ranges rather than single values\n",
    "    df = df[df['Course Code'].str.contains('^[A-Z]{2}\\d{3}$')]\n",
    "          \n",
    "    # Add level column      \n",
    "    df['Level8'] = level == '8'\n",
    "\n",
    "    # tidy_cols, defined above creates new columns for extra info and cleans numerical columns\n",
    "    df = tidy_cols(df)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f24d68-c63b-42a3-b02e-361d13b9da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default parameters for read_cao_pdf for each year\n",
    "pdf_files = {2019: {'8': {},\n",
    "                    '76': {'header_row': 7}},\n",
    "             2018: {'8': {'header_row': 7},\n",
    "                    '76': {'header_row': 7}},\n",
    "             2017: {'8': {},\n",
    "                    '76': {}},\n",
    "             2016: {'8': {'header_row': 6, 'drop_col': [4]},\n",
    "                    '76': {'header_row': 6, 'drop_col': [4]}},\n",
    "             2015: {'8': {'header_row': 14},\n",
    "                    '76': {'header_row': 13}},\n",
    "             2014: {'8': {'header_row': 13},\n",
    "                    '76': {'header_row': 12, 'splitfirst': True}},\n",
    "             2013: {'8': {'header_row': 10},\n",
    "                    '76': {'header_row': 10}},\n",
    "             2012: {'8': {'header_row': 11},\n",
    "                    '76': {'header_row': 10}},\n",
    "             2011: {'8': {'header_row': 23},\n",
    "                    '76': {'header_row': 19}},\n",
    "             2010: {'8': {'header_row': 17},\n",
    "                    '76': {'table_num': 1, 'drop_col': [1], 'merge_drop': 2, 'multiple_tables': True}},\n",
    "             2009: {'8': {'header_row': 17},\n",
    "                    '76': {'header_row': 11}},\n",
    "             2008: {'8': {'header_row': 26},\n",
    "                    '76': {'header_row': 24}},\n",
    "             2005: {'8': {'header_row': 10},\n",
    "                    '76': {'header_row': 9}}\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71763f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_pdfs(pdf_files, type='single'):\n",
    "    \"\"\"\n",
    "    Reads in all the pdf files in the pdf_files dictionary and returns a dictionary\n",
    "    of dataframes with the year as the key\n",
    "    \"\"\"\n",
    "    cao_dfs = {}\n",
    "    for year, levels in pdf_files.items():\n",
    "        \n",
    "        cao_dfs[year] = {}\n",
    "        for level, params in levels.items():\n",
    "            file_path = os.path.join(data_dir, 'cao_' + str(year) + '_lvl' + level + '.pdf')\n",
    "            if type == 'single':\n",
    "                cao_dfs[year][level] = read_cao_pdf(file_path, **params)\n",
    "            elif type == 'multiple':\n",
    "                cao_dfs[year][level] = read_cao_multicol(file_path, **params)\n",
    "            else:\n",
    "                raise ValueError('type must be either single or multiple')\n",
    "\n",
    "        cao_dfs[year] = pd.concat([cao_dfs[year]['8'], cao_dfs[year]['76']], axis=0, ignore_index=True)\n",
    "        \n",
    "    return cao_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619ce55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data held in a multiple-column-per-page and multiple-page-per-column table in a PDF file\n",
    "#### 2007 and 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48bd363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_multicol(pdf_path, top, height, width, col_locs, runover, header_row=0):\n",
    "#     # distance in points of top of table from top of page, \n",
    "#     # height of table, and width of table\n",
    "#     top, height, width  = (18.875, 568, 246)\n",
    "\n",
    "#     # distance in points of left edge of page column from left edge of page\n",
    "#     col_locs = (18.375, 260.625, 509.625)\n",
    "\n",
    "#     # Table columns run over to next page in most cases\n",
    "#     # The 'runover' variable holds the number of rows in each page\n",
    "#     # that need to be push back up to the previous page\n",
    "#     runover = [0, 2, 4, 0, 0]\n",
    "\n",
    "    # Extract level from path\n",
    "    level = re.search('lvl(.+)\\.', pdf_path).group(1)\n",
    "\n",
    "    # List to hold dataframes\n",
    "    tables = []\n",
    "    for i, col_loc in enumerate(col_locs):\n",
    "        # table area in this page column\n",
    "        area = [top, col_loc, top + height, col_loc + width]\n",
    "        # tables will be a list containing three lists, one holding all of the left page column tables, \n",
    "        # one all the centre column tables, and one all of the right column tables\n",
    "        tables.append(read_pdf(pdf_path, pages=\"all\", multiple_tables=True, area=area, pandas_options={'header': None}))\n",
    "\n",
    "    # All of those above can be shifted to the left\n",
    "    # Iterate through lists of lists of dataframes\n",
    "    for df_list in tables:\n",
    "        # Iterate through all dataframes in list\n",
    "        for df in df_list:\n",
    "            # If the dataframe has more than four columns\n",
    "            if len(df.columns) > 4:\n",
    "                # the last column is not wanted\n",
    "                extra_col = df.iloc[:,-1]\n",
    "                # if the number of rows in the dataframe \n",
    "                # is less than the number of na values in \n",
    "                # the extra row then there must be some data \n",
    "                # in the extra column that needs to be moved \n",
    "                # before the column is dropped\n",
    "                if df.shape[0] > extra_col.isna().sum():\n",
    "                    # Find the rows which hold data in the extra column \n",
    "                    # and shift all values one cell to the left\n",
    "                    df[extra_col.notna()] = df[extra_col.notna()].shift(periods=-1, axis=1)\n",
    "                \n",
    "                # drop the extra column\n",
    "                df.drop(df.columns[4], axis=1, inplace=True)\n",
    "\n",
    "    # Transpose table list so that each sublist represents a page\n",
    "    # and each dataframe represents a column in that page\n",
    "    pages = [list(table) for table in zip_longest(*tables)]\n",
    "\n",
    "    #Iterate over lists representing pages, starting with page 2 as \n",
    "    # page one has no previous page to push rows up to\n",
    "    for page in range(1, len(pages)):\n",
    "        # Get the number of rows which have run on from the previous page\n",
    "        num_rows = runover[page]\n",
    "        # iterate through dataframes representing page columns\n",
    "        for i, col in enumerate(pages[page]):\n",
    "            if col is not None:\n",
    "                # copy the runover rows\n",
    "                rows = col.head(num_rows)\n",
    "                # append the runover rows to the dataframes representing the previous page's columns\n",
    "                pages[page - 1][i] = pages[page - 1][i].append(rows, ignore_index=True)\n",
    "                # drop the runover rows from the dataframes they had run over into\n",
    "                col.drop(rows.index, inplace=True)\n",
    "\n",
    "    # Flatten the list so that all data frames are in the \n",
    "    # correct order for concatenation\n",
    "    table_cols = [col for page in pages for col in page]\n",
    "\n",
    "    # The last two elements are None so remove them\n",
    "    del(table_cols[-2:])\n",
    "\n",
    "    # concatenate all of the column tables into a single dataframe\n",
    "    df = pd.concat(table_cols)\n",
    "    # Set column names\n",
    "    df.columns = ['Course Code', 'Course Name', 'EOS', 'Mid']\n",
    "    # reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Remove all rows up to the header row which contain no data\n",
    "    df.drop(df.index[0:header_row], inplace=True)\n",
    "\n",
    "    # Remove rows where all values are NaN\n",
    "    df.drop(df.index[pd.isnull(df).all(1)], inplace=True)\n",
    "\n",
    "    # Rows in which Course Code is NaN and Course Name is not all caps, \n",
    "    # non-alphanumeric characters, and the words of, the, and and \n",
    "    # do not contain usable data\n",
    "    df.drop(df[~(df['Course Name'].str.contains(\n",
    "        '^[A-Z\\s\\Woftheand]+$', na=False)) & df['Course Code'].isna()], axis=1).index\n",
    "\n",
    "    # Create a new column in the dataframe for institution name \n",
    "    # identify institution name rows as those containing null course codes\n",
    "    # and add those institution names to the new institution column\n",
    "    df['Institution'] = df[df['Course Code'].isnull() | df['Course Code'].str.contains('Code')]['Course Name']\n",
    "\n",
    "    # Some Institution rows have the word 'Code' in the Course Code column (in 2006 pdfs)\n",
    "    \n",
    "\n",
    "    # Fill empty fields in the institution column with the most recent non-na field\n",
    "    df['Institution'] = df['Institution'].fillna(method='ffill')\n",
    "\n",
    "    # Remove rows containing only institution names\n",
    "    df = df[df['Course Code'].notna()]\n",
    "\n",
    "    # Add level column\n",
    "    df['Level8'] = level == '8'\n",
    "\n",
    "    # reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Search in course code column reveals some bad rows\n",
    "    # Drop any rows where Course Code does not follow /d/d/D/D/D pattern\n",
    "    df.drop(df[~df['Course Code'].str.contains('^\\D\\D\\d\\d\\d$', regex=True)].index, inplace=True)\n",
    "\n",
    "    # add remaining columns and clean up\n",
    "    df = tidy_cols(df)\n",
    "        \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca86ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default parameters for read_cao_broadsheet() for each year\n",
    "pdf_multicol_files = {\n",
    "    2007: {'8': {'top': 18.875, 'height': 568, 'width': 246,\n",
    "                 'col_locs': [18.375, 260.625, 509.625],\n",
    "                 'runover': [0, 2, 4, 6, 7, 9, 0],\n",
    "                 'header_row': 18},\n",
    "           '76': {'top': 18.875, 'height': 568, 'width': 246,\n",
    "                  'col_locs': [18.375, 260.625, 509.625],\n",
    "                  'runover': [0, 2, 4, 0, 0],\n",
    "                  'header_row': 15}},\n",
    "    2006: {'8': {'top': 18.125, 'height': 556.5, 'width': 324.75,\n",
    "                 'col_locs': [19.125, 353.625],\n",
    "                 'runover': [0, 0, 4, 7, 7, 12, 15, 11, 20],\n",
    "                 'header_row': 20},\n",
    "           '76': {'top': 18.125, 'height': 556.5, 'width': 324.75,\n",
    "                  'col_locs': [19.125, 353.625],\n",
    "                  'runover': [0, 0, 5, 7, 5, 14],\n",
    "                  'header_row': 13}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d539717",
   "metadata": {},
   "source": [
    "At this point we have three functions; `read_cao_htmls()`, `read_cao_excel()`, and `read_cao_pdfs()`, which between them will read all of the CAO points data from 2001 to 2021, assuming it is accessible on disk, and return a dict of pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170e3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_cao(write_csv=False, csv_loc=None, ret='df'):\n",
    "        \n",
    "    # Read all data files and construct dictionaries of dataframes\n",
    "    dfs1 = read_cao_htmls(html_files)\n",
    "    # read_cao_excel() returns a single dataframe rather than a dict\n",
    "    df2  = read_cao_excel()\n",
    "    dfs3 = read_cao_pdfs(pdf_files)\n",
    "    dfs4 = read_cao_pdfs(pdf_multicol_files, type='multiple')\n",
    "\n",
    "    # Merge dicts and dataframes to a single dict keyed by year\n",
    "    dfs = dfs1 | dfs3 | dfs4 | {2020:df2}\n",
    "\n",
    "    # Change int dict keys to strings\n",
    "    dfs = {str(key) : dfs[key] for key in dfs}\n",
    "\n",
    "    # Set index in dataframes to course code so that \n",
    "    # they are joined on course code when concatenated\n",
    "    for df in dfs.values():\n",
    "        df.set_index('Course Code', inplace=True)\n",
    "    \n",
    "    # Construct single multiindex dataframe holding CAO data from all years\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    # If write_csv flag is True..\n",
    "    if write_csv:\n",
    "        # Write a csv for each year's data\n",
    "        for year in dfs:\n",
    "            filename = os.path.join(csv_loc, f'cao_{year}.csv')\n",
    "            dfs[year].to_csv(filename)\n",
    "        # Write a single csv for all data\n",
    "        df.to_csv('data/cao/csv/cao_2001-2021.csv')\n",
    "\n",
    "    # Return either a dict of dataframes or a single multiindex dataframe\n",
    "    if ret == 'dict':\n",
    "        return dfs\n",
    "    elif ret == 'df':\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError('ret must be either \"dict\" or \"df\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bae166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data from original sources and write resulting csv's\n",
    "dfs = read_all_cao(write_csv=True, csv_loc='./data/cao/csv', ret='dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369c7a5",
   "metadata": {},
   "source": [
    "## Analysing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ee9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiindex dataframe with 2001-2021 data from csv\n",
    "df = pd.read_csv('data/cao/csv/cao_2001-2021.csv', header=[0,1], index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d44ae0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">2021</th>\n",
       "      <th>2004</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th colspan=\"9\" halign=\"left\">2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>EOS</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Level8</th>\n",
       "      <th>Test</th>\n",
       "      <th>Not All</th>\n",
       "      <th>AQA</th>\n",
       "      <th>New Comp</th>\n",
       "      <th>Course Name</th>\n",
       "      <th>...</th>\n",
       "      <th>New Comp</th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>EOS</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Level8</th>\n",
       "      <th>Test</th>\n",
       "      <th>Not All</th>\n",
       "      <th>AQA</th>\n",
       "      <th>New Comp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Course Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL801</th>\n",
       "      <td>Software Design for Virtual Reality and Gaming...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Design with Virtual Reality and Gaming</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>303.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL802</th>\n",
       "      <td>Software Design in Artificial Intelligence for...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Design with Artificial Intelligence f...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>332.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL803</th>\n",
       "      <td>Software Design for Mobile Apps and Connected ...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Design with Mobile Apps and Connected...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>337.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL805</th>\n",
       "      <td>Computer Engineering for Network Infrastructur...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Engineering with Network Infrastructure</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>333.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL810</th>\n",
       "      <td>Quantity Surveying                            ...</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quantity Surveying</td>\n",
       "      <td>Athlone Institute of Technology</td>\n",
       "      <td>326.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU971</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contemporary Visual Culture</td>\n",
       "      <td>Technological University Dublin</td>\n",
       "      <td>290.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative and Cultural Industries</td>\n",
       "      <td>Technological University Dublin</td>\n",
       "      <td>281.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Print Media Technology and Management</td>\n",
       "      <td>Technological University Dublin</td>\n",
       "      <td>289.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Early Childhood Care and Education</td>\n",
       "      <td>Technological University Dublin</td>\n",
       "      <td>270.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Early Childhood Care and Education</td>\n",
       "      <td>Technological University Dublin</td>\n",
       "      <td>230.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3191 rows Ã— 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          2021  \\\n",
       "                                                   Course Name   \n",
       "Course Code                                                      \n",
       "AL801        Software Design for Virtual Reality and Gaming...   \n",
       "AL802        Software Design in Artificial Intelligence for...   \n",
       "AL803        Software Design for Mobile Apps and Connected ...   \n",
       "AL805        Computer Engineering for Network Infrastructur...   \n",
       "AL810        Quantity Surveying                            ...   \n",
       "...                                                        ...   \n",
       "TU971                                                      NaN   \n",
       "TU972                                                      NaN   \n",
       "TU986                                                      NaN   \n",
       "TU993                                                      NaN   \n",
       "TU994                                                      NaN   \n",
       "\n",
       "                                                                               \\\n",
       "                                 Institution    EOS Mid Level8   Test Not All   \n",
       "Course Code                                                                     \n",
       "AL801        Athlone Institute of Technology  300.0 NaN   True  False   False   \n",
       "AL802        Athlone Institute of Technology  313.0 NaN   True  False   False   \n",
       "AL803        Athlone Institute of Technology  350.0 NaN   True  False   False   \n",
       "AL805        Athlone Institute of Technology  321.0 NaN   True  False   False   \n",
       "AL810        Athlone Institute of Technology  328.0 NaN   True  False   False   \n",
       "...                                      ...    ...  ..    ...    ...     ...   \n",
       "TU971                                    NaN    NaN NaN    NaN    NaN     NaN   \n",
       "TU972                                    NaN    NaN NaN    NaN    NaN     NaN   \n",
       "TU986                                    NaN    NaN NaN    NaN    NaN     NaN   \n",
       "TU993                                    NaN    NaN NaN    NaN    NaN     NaN   \n",
       "TU994                                    NaN    NaN NaN    NaN    NaN     NaN   \n",
       "\n",
       "                                   2004  ...     2006  \\\n",
       "               AQA New Comp Course Name  ... New Comp   \n",
       "Course Code                              ...            \n",
       "AL801        False    False         NaN  ...      NaN   \n",
       "AL802        False    False         NaN  ...      NaN   \n",
       "AL803        False    False         NaN  ...      NaN   \n",
       "AL805        False    False         NaN  ...      NaN   \n",
       "AL810        False    False         NaN  ...      NaN   \n",
       "...            ...      ...         ...  ...      ...   \n",
       "TU971          NaN      NaN         NaN  ...      NaN   \n",
       "TU972          NaN      NaN         NaN  ...      NaN   \n",
       "TU986          NaN      NaN         NaN  ...      NaN   \n",
       "TU993          NaN      NaN         NaN  ...      NaN   \n",
       "TU994          NaN      NaN         NaN  ...      NaN   \n",
       "\n",
       "                                                          2020  \\\n",
       "                                                   Course Name   \n",
       "Course Code                                                      \n",
       "AL801          Software Design with Virtual Reality and Gaming   \n",
       "AL802        Software Design with Artificial Intelligence f...   \n",
       "AL803        Software Design with Mobile Apps and Connected...   \n",
       "AL805         Computer Engineering with Network Infrastructure   \n",
       "AL810                                       Quantity Surveying   \n",
       "...                                                        ...   \n",
       "TU971                              Contemporary Visual Culture   \n",
       "TU972                         Creative and Cultural Industries   \n",
       "TU986                    Print Media Technology and Management   \n",
       "TU993                       Early Childhood Care and Education   \n",
       "TU994                       Early Childhood Care and Education   \n",
       "\n",
       "                                                                          \\\n",
       "                                 Institution    EOS    Mid Level8   Test   \n",
       "Course Code                                                                \n",
       "AL801        Athlone Institute of Technology  303.0  367.0   True  False   \n",
       "AL802        Athlone Institute of Technology  332.0  382.0   True  False   \n",
       "AL803        Athlone Institute of Technology  337.0  360.0   True  False   \n",
       "AL805        Athlone Institute of Technology  333.0  360.0   True  False   \n",
       "AL810        Athlone Institute of Technology  326.0  352.0   True  False   \n",
       "...                                      ...    ...    ...    ...    ...   \n",
       "TU971        Technological University Dublin  290.0  320.0   True  False   \n",
       "TU972        Technological University Dublin  281.0  369.0   True  False   \n",
       "TU986        Technological University Dublin  289.0  300.0   True  False   \n",
       "TU993        Technological University Dublin  270.0  311.0   True  False   \n",
       "TU994        Technological University Dublin  230.0  304.0   True  False   \n",
       "\n",
       "                                     \n",
       "            Not All    AQA New Comp  \n",
       "Course Code                          \n",
       "AL801         False  False    False  \n",
       "AL802         False  False    False  \n",
       "AL803         False  False    False  \n",
       "AL805         False  False    False  \n",
       "AL810         False  False    False  \n",
       "...             ...    ...      ...  \n",
       "TU971         False  False    False  \n",
       "TU972         False  False    False  \n",
       "TU986         False  False    False  \n",
       "TU993         False  False    False  \n",
       "TU994         False  False    False  \n",
       "\n",
       "[3191 rows x 189 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070dc7a5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb21d15",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589f008",
   "metadata": {},
   "source": [
    "[1] https://www.independent.ie/life/family/learning/understanding-your-cao-course-guide-26505318.html\n",
    "\n",
    "\n",
    "https://tabula-py.readthedocs.io/en/latest/faq.html#how-to-use-area-option"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff05c7be86f22d0e747ff85fe7c240453a96afc5d2ecdb04243977de5be4b895"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
