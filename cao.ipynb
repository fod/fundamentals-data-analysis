{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb758f0",
   "metadata": {},
   "source": [
    "# CAO Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47267f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The CAO points data, available from the [CAO website](http://www.cao.ie), is published in a different format for each of the years 2019, 2020, and 2021. Each year's data, therefore, requires a different approach to acquisition, conversion to pandas DataFrame, and cleaning. The 2019 data is published in two PDF files; one for level 8 courses, and one for levels 6 and 7. The 2020 data is published as an Excel spreadsheet, and the 2021 data as preformatted text in a HTML web page.\n",
    "\n",
    "The attributes of interest for comparison between the various years' datasets are `Course Code`, `Course Name`, `Institution Name`, `EOS`, which is the number of points achieved by the last applicant to be offered a place on the course, and `Mid`, which is the mid point between the number of points held by the highest point score and the lowest point score of the applicants offered a place on the course [1]. The 2021 data does not explicitly contain an either an `EOS` or a `Mid` column. It does provide the *Round 1* and *Round 2* points required for entry into each course as `RND1` and `RND2`. Examination of the 2020 data, which contains both an `EOS` field *and* `RND1` and `RND2` fields demonstrates that the `EOS` field is equal to the `RND2` value if it exists, otherwise the `RND1` value (```EOS = RND1 if RND1 else RND2```). As for the `Mid` field; this information does not appear to be available yet for the 2021 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e8574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Data analysis library\n",
    "import pandas as pd\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# PDF table parsing\n",
    "from tabula import read_pdf\n",
    "# Retrieval of resources from WWW\n",
    "import requests\n",
    "# URL construction\n",
    "from requests.compat import urljoin\n",
    "# Various utilities, mainly path construction\n",
    "import os\n",
    "# Creation of datetime strings for filenames\n",
    "from datetime import datetime\n",
    "# Regular expressions\n",
    "import re\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from itertools import zip_longest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4508744",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Acquiring the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e93f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of CAO points data\n",
    "base_url = 'http://www2.cao.ie/points/'\n",
    "# Local data directory\n",
    "data_dir = 'data/cao'\n",
    "backup_dir = 'data/cao/backup'\n",
    "\n",
    "# Dictionary of source file names mapped to the file names that will be used locally\n",
    "points_urls  = ({'l8.php'                  : 'cao_2021_lvl8.html',\n",
    "                 'l76.php'                 : 'cao_2021_lvl76.html',\n",
    "                 'CAOPointsCharts2020.xlsx': 'cao_2020_lvl876.xlsx'\n",
    "                 })\n",
    "\n",
    "# The rest of points_urls can be assembled programmatically\n",
    "# as filenames follow a pattern\n",
    "\n",
    "# List of years as 2-digit strings from 2019 to 2005\n",
    "years = [str(i).zfill(2) for i in range(19, 4, -1)]\n",
    "# For each year (2019 to 2005)\n",
    "for year in years:\n",
    "    levels = ('lvl8', 'lvl76')\n",
    "    # Using a separate local_levels variable allows consistent local \n",
    "    # file naming in cases where the remote files are inconsistently named\n",
    "    local_levels = levels\n",
    "    \n",
    "    # 2011 and 2012 data is missing second 'l' from filenames\n",
    "    if year in ('12', '11'):\n",
    "        levels = ('lv8', 'lv76')\n",
    "        \n",
    "    # For each level \n",
    "    for level, local_level in zip(levels, local_levels):\n",
    "        # construct remote filename\n",
    "        remote_name = level + '_' + year + '.pdf'\n",
    "\n",
    "        # construct local filename\n",
    "        local_name = 'cao_20' + year + '_' + local_level + '.pdf'\n",
    "        # Add remote and local filenames as keys and values in points_urls dict\n",
    "        points_urls[remote_name] = local_name\n",
    "\n",
    "# List of years as 2-digit strings from 2004 to 2001\n",
    "years = [str(i).zfill(2) for i in range(4, 0, -1)]\n",
    "for year in years:\n",
    "    levels = ('deg', 'dip')\n",
    "    local_levels = ('lvl8', 'lvl76')\n",
    "\n",
    "    for level, local_level in zip(levels, local_levels):\n",
    "        remote_name = level + year + '.htm'\n",
    "        local_name = 'cao_20' + year + '_' + local_level + '.html'\n",
    "        points_urls[remote_name] = local_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cao_source_data(base_url, points_urls, data_dir, backup_dir, verbose=False):\n",
    "    # for each of the source files \n",
    "    for url in (points_urls):\n",
    "        # construct url and fetch content\n",
    "        response = requests.get(urljoin(base_url, url))\n",
    "\n",
    "        try:\n",
    "            # attempt to open any previously downloaded local file\n",
    "            with open(os.path.join(data_dir, points_urls[url]), \"rb\") as f:\n",
    "                # Calculate md5 hashes for the local file and the remote file\n",
    "                md5_local = hashlib.md5(f.read()).hexdigest()\n",
    "                md5_response = hashlib.md5(response.content).hexdigest()\n",
    "\n",
    "                # Set write_flag to False if the hashes are equal and True if they are not\n",
    "                write_flag = (md5_local != md5_response)\n",
    "        except FileNotFoundError:\n",
    "            # if the local file does not exist set the write_flag to True and move on\n",
    "            write_flag = True\n",
    "\n",
    "        # If the write_flag is True\n",
    "        if write_flag:\n",
    "            if verbose:\n",
    "                print(f\"File: {points_urls[url]} has changed since last download. Updating...\")\n",
    "            # split the filename into name and extension\n",
    "            fname, extension = os.path.splitext(points_urls[url])\n",
    "            # construct unique filename by inserting datetime string between filename and extension\n",
    "            filename = fname + datetime.now().strftime(\"_%Y%m%d_%H%M%S\") + extension\n",
    "\n",
    "            # write the timestamped remote file to the backup directory\n",
    "            with open(os.path.join(backup_dir, filename), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # also write the remote file to the data directory, overwriting any previous file\n",
    "            with open(os.path.join(data_dir, points_urls[url]), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"File: {points_urls[url]} has not changed since last download. Skipping...\")\n",
    "                \n",
    "get_cao_source_data(base_url=base_url, \n",
    "                    points_urls=points_urls, \n",
    "                    data_dir=data_dir, \n",
    "                    backup_dir=backup_dir, \n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a8fca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2021 Points Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7327f295-9c6b-4e0c-9a95-901028814914",
   "metadata": {},
   "outputs": [],
   "source": [
    "l8 = os.path.join(data_dir, 'cao_2021_lvl8.html')\n",
    "l76 = os.path.join(data_dir, 'cao_2021_lvl76.html')\n",
    "\n",
    "# Regular expression to capture fields from lines\n",
    "# Lines consist of 2 letters and 3 numbers, comprising the course code; some whitespace; \n",
    "# 50 characters which start with a non-whitespace character; some more whitespace;\n",
    "# some optional non whitespace characters comprising round 1 points; some more whitespace;\n",
    "# and, optionally some more non-whitespace characters comprising round 2 points if present\n",
    "re_fields = re.compile('^([A-Z]{2}[0-9]{3})\\s+(\\S.{49})\\s+(\\S+)?\\s+(\\S+)?')\n",
    "\n",
    "# array to hold matched groups\n",
    "data = []\n",
    "\n",
    "for datafile, level in zip((l8, l76), (8, 76)):\n",
    "    # encoding=cp1252 necessary to decode some characters on page\n",
    "    with open(datafile, 'r', encoding='cp1252') as f:\n",
    "        for line in f:\n",
    "            match = re.match(re_fields, line)\n",
    "            if match:\n",
    "                fields = list(match.groups())\n",
    "                fields.append(level)\n",
    "                data.append(fields)\n",
    "\n",
    "# column names\n",
    "columns = ['Course Code', 'Course Name', 'Rnd1', 'Rnd2', 'Level']\n",
    "df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedff052",
   "metadata": {},
   "source": [
    "Create new columns to hold information currently designated by *'s and #'s in numeric columns\n",
    "\n",
    "Create new column indicating whether the course requires a test, interview or portfolio\n",
    "This is indicated by a '#' in the Rnd1 or Rnd2 column\n",
    "df['Test'] = df['Rnd1'].str.contains('#', na=False) | df['Rnd2'].str.contains('#', na=False)\n",
    "\n",
    "Create a column indicating courses where not all applicants at Rnd1 point score were offered a place\n",
    "This is indicated by a '*' in the Rnd1 or Rnd2 column\n",
    "df['Not All'] = df['Rnd1'].str.contains('\\*', na=False) | df['Rnd2'].str.contains('\\*', na=False)\n",
    "\n",
    "Create a new column for AQA meaning All Qualified Applicants were offered a place\n",
    "df['AQA'] = df['Rnd1'].str.contains('AQA', na=False) | df['Rnd2'].str.contains('AQA', na=False)\n",
    "\n",
    "Create a new column for 'New competition for available places' which seems to be courses \n",
    "for which the points have increased in round 2. Only occurs in level 76 and is indicated \n",
    "by a 'v' in 'Rnd2' column\n",
    "df['New Comp'] = df['Rnd1'].str.contains('v', na=False) | df['Rnd2'].str.contains('v', na=False)\n",
    "\n",
    "Generate 'EOS' column. == Rnd2 if it exists, otherwise Rnd1\n",
    "df['EOS'] = np.where(df['Rnd2'].isnull(), df['Rnd1'], df['Rnd2'])\n",
    "\n",
    "Remove Non-digits from Rnd1 and Rnd2 columns and convert columns to numeric values, \n",
    "with NaNs where values are missing (errors = 'coerce')\n",
    "(Because NaN is a float, the whole columns must be floats)\n",
    "df['Rnd1'] = pd.to_numeric(df['Rnd1'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "df['Rnd2'] = pd.to_numeric(df['Rnd2'].str.replace('[^0-9]+', '', regex=True), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3bc5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Code</th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Rnd1</th>\n",
       "      <th>Rnd2</th>\n",
       "      <th>Level</th>\n",
       "      <th>Test</th>\n",
       "      <th>Not All</th>\n",
       "      <th>AQA</th>\n",
       "      <th>New Comp</th>\n",
       "      <th>EOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL801</td>\n",
       "      <td>Software Design for Virtual Reality and Gaming...</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL802</td>\n",
       "      <td>Software Design in Artificial Intelligence for...</td>\n",
       "      <td>313</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL803</td>\n",
       "      <td>Software Design for Mobile Apps and Connected ...</td>\n",
       "      <td>350</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL805</td>\n",
       "      <td>Computer Engineering for Network Infrastructur...</td>\n",
       "      <td>321</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL810</td>\n",
       "      <td>Quantity Surveying                            ...</td>\n",
       "      <td>328</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL811</td>\n",
       "      <td>Civil Engineering                             ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AL820</td>\n",
       "      <td>Mechanical and Polymer Engineering            ...</td>\n",
       "      <td>327</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AL830</td>\n",
       "      <td>General Nursing                               ...</td>\n",
       "      <td>451*</td>\n",
       "      <td>444</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AL832</td>\n",
       "      <td>Mental Health Nursing                         ...</td>\n",
       "      <td>440*</td>\n",
       "      <td>431</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AL835</td>\n",
       "      <td>Pharmacology                                  ...</td>\n",
       "      <td>356</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AL836</td>\n",
       "      <td>Nutrition and Health Science                  ...</td>\n",
       "      <td>346</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AL837</td>\n",
       "      <td>Sports Science with Exercise Physiology       ...</td>\n",
       "      <td>357</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AL838</td>\n",
       "      <td>Biotechnology                                 ...</td>\n",
       "      <td>324</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AL839</td>\n",
       "      <td>Microbiology                                  ...</td>\n",
       "      <td>325</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AL840</td>\n",
       "      <td>Pharmaceutical Sciences                       ...</td>\n",
       "      <td>346</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AL841</td>\n",
       "      <td>Athletic and Rehabilitation Therapy           ...</td>\n",
       "      <td>477</td>\n",
       "      <td>476*</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AL842</td>\n",
       "      <td>Bioveterinary Science                         ...</td>\n",
       "      <td>338</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AL843</td>\n",
       "      <td>Physical Activity and Health Science          ...</td>\n",
       "      <td>306</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AL849</td>\n",
       "      <td>Culinary Entrepreneurship                     ...</td>\n",
       "      <td>297</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AL850</td>\n",
       "      <td>Business                                      ...</td>\n",
       "      <td>309</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Course Code                                        Course Name  Rnd1  Rnd2  \\\n",
       "0        AL801  Software Design for Virtual Reality and Gaming...   300  None   \n",
       "1        AL802  Software Design in Artificial Intelligence for...   313  None   \n",
       "2        AL803  Software Design for Mobile Apps and Connected ...   350  None   \n",
       "3        AL805  Computer Engineering for Network Infrastructur...   321  None   \n",
       "4        AL810  Quantity Surveying                            ...   328  None   \n",
       "5        AL811  Civil Engineering                             ...  None  None   \n",
       "6        AL820  Mechanical and Polymer Engineering            ...   327  None   \n",
       "7        AL830  General Nursing                               ...  451*   444   \n",
       "8        AL832  Mental Health Nursing                         ...  440*   431   \n",
       "9        AL835  Pharmacology                                  ...   356  None   \n",
       "10       AL836  Nutrition and Health Science                  ...   346  None   \n",
       "11       AL837  Sports Science with Exercise Physiology       ...   357  None   \n",
       "12       AL838  Biotechnology                                 ...   324  None   \n",
       "13       AL839  Microbiology                                  ...   325  None   \n",
       "14       AL840  Pharmaceutical Sciences                       ...   346  None   \n",
       "15       AL841  Athletic and Rehabilitation Therapy           ...   477  476*   \n",
       "16       AL842  Bioveterinary Science                         ...   338  None   \n",
       "17       AL843  Physical Activity and Health Science          ...   306  None   \n",
       "18       AL849  Culinary Entrepreneurship                     ...   297  None   \n",
       "19       AL850  Business                                      ...   309  None   \n",
       "\n",
       "    Level   Test  Not All    AQA  New Comp    EOS  \n",
       "0       8  False    False  False     False  300.0  \n",
       "1       8  False    False  False     False  313.0  \n",
       "2       8  False    False  False     False  350.0  \n",
       "3       8  False    False  False     False  321.0  \n",
       "4       8  False    False  False     False  328.0  \n",
       "5       8  False    False  False     False    NaN  \n",
       "6       8  False    False  False     False  327.0  \n",
       "7       8  False     True  False     False  444.0  \n",
       "8       8  False     True  False     False  431.0  \n",
       "9       8  False    False  False     False  356.0  \n",
       "10      8  False    False  False     False  346.0  \n",
       "11      8  False    False  False     False  357.0  \n",
       "12      8  False    False  False     False  324.0  \n",
       "13      8  False    False  False     False  325.0  \n",
       "14      8  False    False  False     False  346.0  \n",
       "15      8  False     True  False     False  476.0  \n",
       "16      8  False    False  False     False  338.0  \n",
       "17      8  False    False  False     False  306.0  \n",
       "18      8  False    False  False     False  297.0  \n",
       "19      8  False    False  False     False  309.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcols = {'Test': '#', 'Not All': '\\*', 'AQA': 'AQA', 'New Comp': 'v'}\n",
    "\n",
    "for k, v in newcols.items():\n",
    "    df[k] = df['Rnd1'].str.contains(v, na=False) | df['Rnd2'].str.contains(v, na=False)\n",
    "\n",
    "# Generate 'EOS' column. == Rnd2 if it exists, otherwise Rnd1\n",
    "df['EOS'] = np.where(df['Rnd2'].isnull(), df['Rnd1'], df['Rnd2'])\n",
    "\n",
    "# Remove Non-digits from Rnd1 and Rnd2 columns and convert columns to numeric values, \n",
    "# with NaNs where values are missing (errors = 'coerce')\n",
    "# (Because NaN is a float, the whole columns must be floats)\n",
    "df['EOS'] = pd.to_numeric(df['EOS'].str.replace('[^0-9]+', '', regex=True), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e10452",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2020 Points Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15978aa3",
   "metadata": {},
   "source": [
    "1. Read Excel file using pandas.read_excel, specifying header row, desired columns, and row names\n",
    "2. Create and populate 'Test', 'Not All', 'Matric', and 'AQA' columns\n",
    "3. Remove all non-numeric characters from 'EOS' and 'Mid' and convert to numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d8aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_cols(df):\n",
    "    \n",
    "    cols = ['Test', 'Not All', 'Matric', 'AQA']\n",
    "    markers = ['#', '*', 'mat', 'AQA']\n",
    "\n",
    "    for col, marker in zip(cols, markers):\n",
    "        df[col] = df['EOS'].str.replace('\\s', '', regex=True).str.contains(marker, na=False, regex=False)\n",
    "\n",
    "    for col in ('EOS', 'Mid'):\n",
    "        # Cast each point col to string so they can be cleaned up using string methods\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "        # Some pdfs have second point values in parentheses \n",
    "        # indicating new competition for additional places which must be removed\n",
    "        # or the two point values will be concatenated in the next step\n",
    "        df[col] = df[col].str.replace('\\(.+\\)', '', regex=True)\n",
    "        \n",
    "        # Remove non digits and decimal points outside numbers\n",
    "        df[col] = df[col].str.replace('[^0-9.]', '', regex=True).str.strip(\".\")\n",
    "\n",
    "        # Cast points columns to float\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce', downcast='float')  \n",
    "            \n",
    "    # Reset the index\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6471e278-94a6-4bc3-96b1-c8c1d9e13683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Course Code</th>\n",
       "      <th>EOS</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Institution Name</th>\n",
       "      <th>Test</th>\n",
       "      <th>Not All</th>\n",
       "      <th>Matric</th>\n",
       "      <th>AQA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>International Business</td>\n",
       "      <td>AC120</td>\n",
       "      <td>209.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>American College</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>AC137</td>\n",
       "      <td>252.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>American College</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Year Art &amp; Design (Common Entry,portfolio)</td>\n",
       "      <td>AD101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National College of Art and Design</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graphic Design and Moving Image Design (portfo...</td>\n",
       "      <td>AD102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National College of Art and Design</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Textile &amp; Surface Design and Jewellery &amp; Objec...</td>\n",
       "      <td>AD103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National College of Art and Design</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Course Name Course Code    EOS  \\\n",
       "0                             International Business       AC120  209.0   \n",
       "1                                       Liberal Arts       AC137  252.0   \n",
       "2   First Year Art & Design (Common Entry,portfolio)       AD101    NaN   \n",
       "3  Graphic Design and Moving Image Design (portfo...       AD102    NaN   \n",
       "4  Textile & Surface Design and Jewellery & Objec...       AD103    NaN   \n",
       "\n",
       "     Mid                    Institution Name   Test  Not All  Matric    AQA  \n",
       "0  280.0                    American College  False    False   False  False  \n",
       "1  270.0                    American College  False    False   False  False  \n",
       "2    NaN  National College of Art and Design   True    False    True  False  \n",
       "3    NaN  National College of Art and Design   True    False    True  False  \n",
       "4    NaN  National College of Art and Design   True    False    True  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2020 = pd.read_excel(os.path.join(data_dir, 'cao_2020_lvl876.xlsx'), \n",
    "                       header=10, \n",
    "                       usecols=\"B,C,H,I,J,L\", \n",
    "                       names=['Course Name', 'Course Code', 'EOS', 'EOS *', 'Mid', 'Institution Name'],\n",
    "                       converters={'EOS':str,'Mid':str})\n",
    "\n",
    "# Asterisks usually found in EOS are in a separate col in this dataset\n",
    "# Move asterisks to EOS so generic parser can be used\n",
    "df2020['EOS'] = np.where(df2020['EOS *'].str.contains('*', na=False, regex=False), \n",
    "    df2020['EOS'] + '*', df2020['EOS']) \n",
    "df2020 = df2020.drop('EOS *', axis=1)\n",
    "\n",
    "df2020 = tidy_cols(df2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20791673",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2019 Points Data\n",
    "\n",
    "The 2019 points data is held in two PDF files, one for level 8 courses and one for levels 6 and 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861b0a7",
   "metadata": {},
   "source": [
    "1. Read using tabula.read_pdf()\n",
    "2. If necessary remove unwanted rows and assign header row\n",
    "3. Fix and rename headers\n",
    "4. Fill in institution column\n",
    "5. Remove rows without course codes\n",
    "6. Create and populate 'Test', 'Not All', 'Matric', and 'AQA' columns\n",
    "7. Remove all non-numeric characters from 'EOS' and 'Mid' and convert to numeric type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a8b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_pdf(pdf_path, header_row=None, splitfirst=False, table_num=0, drop_col=None, merge_drop=None, multiple_tables=False):\n",
    "    \n",
    "    df = read_pdf(pdf_path, pages='all', multiple_tables=multiple_tables)[table_num]\n",
    "\n",
    "    # 2016 data has a ghost column\n",
    "    if drop_col is not None:\n",
    "        if merge_drop is not None:\n",
    "            col1 = df.columns[drop_col[0]]\n",
    "            col2 = df.columns[merge_drop]\n",
    "            df.loc[df[col2].isnull(), col2] = df[col1]\n",
    "            \n",
    "        df.drop(df.columns[drop_col], axis=1, inplace=True)\n",
    "    \n",
    "    df.columns = ['Course Code', 'Course Name', 'EOS', 'Mid']\n",
    "\n",
    "    if header_row is not None:\n",
    "        # df.columns = df.iloc[header_row]\n",
    "        df.rename_axis(None, axis=1, inplace=True)\n",
    "        \n",
    "        # Delete rows up to header_row\n",
    "        df.drop(df.index[range(0, header_row + 1)], axis=0, inplace=True)\n",
    "        \n",
    "    # A missing vertical line causes some the pdf parser to merge rows \n",
    "    # in certain tables (e.g. 2014 levels 6 & 7)\n",
    "    # If that is the case we need to shift column contents to the right \n",
    "    # then split the first column into course code and course name\n",
    "    if splitfirst:\n",
    "        # Create insititution column and add contents of Course Name column where Course Code is empty\n",
    "        df['Institution'] = df[df['Course Code'].isnull()]['Course Name']\n",
    "        # Shift the values in EOS to Mid\n",
    "        df['Mid'] = df['EOS']\n",
    "        # Shift the values in Course Name to EOS\n",
    "        df['EOS'] = df['Course Name']\n",
    "        # Locate rows with institution names (In Course code col) and move them to Institution col\n",
    "        # Skip the first row because its a unique situation dealt with in the first libne of this if block\n",
    "        df.loc[df.index[1:], 'Institution'] = df[~df['Course Code'].str.contains('[A-Z]{2}\\d{3}', na=False)]['Course Code'] \n",
    "        # Extract the course name from the course code column and place in Course Name column\n",
    "        df['Course Name'] = df['Course Code'].str.extract('^\\D\\D\\d{3}(.+)$')\n",
    "        # Extract the course code form the Course Code column and place in Course Code column\n",
    "        df['Course Code'] = df['Course Code'].str.extract('^(\\D\\D\\d{3})')       \n",
    "    else:\n",
    "        # Create a new column in the dataframe for institution name \n",
    "        # identify institution name rows as those containing null course codes\n",
    "        # and add those institution names to the new institution column\n",
    "        df['Institution'] = df[df['Course Code'].isnull()]['Course Name']\n",
    "        #df.rename(columns={'INSTITUTION and COURSE':'Course Name'}, inplace=True)\n",
    "    \n",
    "    # Fill empty fields in the institution column with the most recent non-na field\n",
    "    df['Institution'] = df['Institution'].fillna(method='ffill')\n",
    "    \n",
    "    # Remove rows containing only institution names\n",
    "    df = df[df['Course Code'].notna()]\n",
    "        \n",
    "    # Remove page header rows\n",
    "    df = df[df['Course Code'] != 'Course Code']\n",
    "    \n",
    "    # Remove oddball rows like two subject modratorships with point ranges rather than single values\n",
    "    df = df[df['Course Code'].str.contains('^[A-Z]{2}\\d{3}$')]\n",
    "          \n",
    "    # tidy_cols, defined above creates new columns for extra info and cleans numerical columns\n",
    "    df = tidy_cols(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f24d68-c63b-42a3-b02e-361d13b9da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default parameters for read_cao_pdf for each year\n",
    "pdf_files = {2019: {'8': {},\n",
    "                    '76': {'header_row': 7}},\n",
    "             2018: {'8': {'header_row': 7},\n",
    "                    '76': {'header_row': 7}},\n",
    "             2017: {'8': {},\n",
    "                    '76': {}},\n",
    "             2016: {'8': {'header_row': 6, 'drop_col': [4]},\n",
    "                    '76': {'header_row': 6, 'drop_col': [4]}},\n",
    "             2015: {'8': {'header_row': 14},\n",
    "                    '76': {'header_row': 13}},\n",
    "             2014: {'8': {'header_row': 13},\n",
    "                    '76': {'header_row': 12, 'splitfirst': True}},\n",
    "             2013: {'8': {'header_row': 10},\n",
    "                    '76': {'header_row': 10}},\n",
    "             2012: {'8': {'header_row': 11},\n",
    "                    '76': {'header_row': 10}},\n",
    "             2011: {'8': {'header_row': 23},\n",
    "                    '76': {'header_row': 19}},\n",
    "             2010: {'8': {'header_row': 17},\n",
    "                    '76': {'table_num': 1, 'drop_col': [1], 'merge_drop': 2, 'multiple_tables': True}},\n",
    "             2009: {'8': {'header_row': 17},\n",
    "                    '76': {'header_row': 11}},\n",
    "             2008: {'8': {'header_row': 26},\n",
    "                    '76': {'header_row': 24}},\n",
    "             2005: {'8': {'header_row': 10},\n",
    "                    '76': {'header_row': 9}}\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71763f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cao_pdfs(pdf_files):\n",
    "    \"\"\"\n",
    "    Reads in all the pdf files in the pdf_files dictionary and returns a dictionary\n",
    "    of dataframes with the year as the key\n",
    "    \"\"\"\n",
    "    cao_dfs = {}\n",
    "    for year, pdf_files_year in pdf_files.items():\n",
    "        cao_dfs[year] = {}\n",
    "        for level, pdf_files_level in pdf_files_year.items():\n",
    "            cao_dfs[year][level] = read_cao_pdf(os.path.join(data_dir, 'cao_' + str(year) + '_lvl' + level + '.pdf'), **pdf_files_level)\n",
    "            #print(f\"Year: {year}\\tLevel: {level}\")\n",
    "            #display(cao_dfs[year][level].tail())\n",
    "    \n",
    "    return cao_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3792ba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2019\tLevel: 8\n",
      "Year: 2019\tLevel: 76\n",
      "Year: 2018\tLevel: 8\n",
      "Year: 2018\tLevel: 76\n",
      "Year: 2017\tLevel: 8\n",
      "Year: 2017\tLevel: 76\n",
      "Year: 2016\tLevel: 8\n",
      "Year: 2016\tLevel: 76\n",
      "Year: 2015\tLevel: 8\n",
      "Year: 2015\tLevel: 76\n",
      "Year: 2014\tLevel: 8\n",
      "Year: 2014\tLevel: 76\n",
      "Year: 2013\tLevel: 8\n",
      "Year: 2013\tLevel: 76\n",
      "Year: 2012\tLevel: 8\n",
      "Year: 2012\tLevel: 76\n",
      "Year: 2011\tLevel: 8\n",
      "Year: 2011\tLevel: 76\n",
      "Year: 2010\tLevel: 8\n",
      "Year: 2010\tLevel: 76\n",
      "Year: 2009\tLevel: 8\n",
      "Year: 2009\tLevel: 76\n",
      "Year: 2008\tLevel: 8\n",
      "Year: 2008\tLevel: 76\n",
      "Year: 2005\tLevel: 8\n",
      "Year: 2005\tLevel: 76\n"
     ]
    }
   ],
   "source": [
    "cao_dfs = read_cao_pdfs(pdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d989c7a",
   "metadata": {},
   "source": [
    "#### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6e5d5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_93677/1428649728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add level 8 column to both dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Level 8'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf76\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Level 8'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df8' is not defined"
     ]
    }
   ],
   "source": [
    "# add level 8 column to both dataframes\n",
    "df8['Level 8'] = True\n",
    "df76['Level 8'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conatenate level with levels 6 & 7\n",
    "df = pd.concat([df8, df76], ignore_index=True)\n",
    "\n",
    "# # Rename column names to include year   \n",
    "# df = df.rename({'Course Name': 'Course Name 2019', \n",
    "#                 'EOS': 'EOS 2019', \n",
    "#                 'Mid':'Mid 2019', \n",
    "#                 'Test':'Test 2019', \n",
    "#                 'Not All': 'NotAll 2019',\n",
    "#                 'Matric': 'Matric 2019',\n",
    "#                 'AQA': 'AQA 2019',\n",
    "#                 'Level 8': 'Level8 2019'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe to csv\n",
    "df.to_csv('data/cao/cao_points_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f120621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 8 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2012_lvl8.pdf\")\n",
    "df8_12 = read_cao_pdf(pdf_path, header_row=11)\n",
    "\n",
    "df8_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 76 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2012_lvl76.pdf\")\n",
    "df76_12 = read_cao_pdf(pdf_path, header_row=10)\n",
    "\n",
    "df76_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 8 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2010_lvl8.pdf\")\n",
    "df8_10 = read_cao_pdf(pdf_path, header_row=17)\n",
    "\n",
    "df8_10.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff800a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 76 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2010_lvl76.pdf\")\n",
    "df76_10 = read_cao_pdf(pdf_path, header_row=None, table_num=1, drop_col=[1], merge_drop=2, multiple_tables=True)\n",
    "\n",
    "df76_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15758e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 8 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2009_lvl8.pdf\")\n",
    "df8_09 = read_cao_pdf(pdf_path, header_row=17)\n",
    "\n",
    "df8_09.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5974e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the level 76 pdf, extracting tables into a single dataframe\n",
    "pdf_path = os.path.join(data_dir, \"cao_2009_lvl76.pdf\")\n",
    "df76_09 = read_cao_pdf(pdf_path, header_row=11)\n",
    "\n",
    "df76_09.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619ce55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cao_broadsheet(pdf_path, top, height, width, col_locs, runover, header_row=0):\n",
    "\n",
    "    # List to hold dataframes\n",
    "    tables = []\n",
    "    for i, col_loc in enumerate(col_locs):\n",
    "        # table area in this page column\n",
    "        area = [top, col_loc, top + height, col_loc + width]\n",
    "        # tables will be a list containing three lists, one holding all of the left page column tables, \n",
    "        # one all the centre column tables, and one all of the right column tables\n",
    "        tables.append(read_pdf(pdf_path, pages=\"all\", multiple_tables=True, area=area, pandas_options={'header': None}))\n",
    "\n",
    "    # All of those above can be shifted to the left\n",
    "    # Iterate through lists of lists of dataframes\n",
    "    for df_list in tables:\n",
    "        # Iterate through all dataframes in list\n",
    "        for df in df_list:\n",
    "            # If the dataframe has more than four columns\n",
    "            if len(df.columns) > 4:\n",
    "                # the last column is not wanted\n",
    "                extra_col = df.iloc[:,-1]\n",
    "                # if the number of rows in the dataframe \n",
    "                # is less than the number of na values in \n",
    "                # the extra row then there must be some data \n",
    "                # in the extra column that needs to be moved \n",
    "                # before the column is dropped\n",
    "                if df.shape[0] > extra_col.isna().sum():\n",
    "                    # Find the rows which hold data in the extra column \n",
    "                    # and shift all values one cell to the left\n",
    "                    df[extra_col.notna()] = df[extra_col.notna()].shift(periods=-1, axis=1)\n",
    "                \n",
    "                # drop the extra column\n",
    "                df.drop(df.columns[4], axis=1, inplace=True)\n",
    "\n",
    "    # Transpose table list so that each sublist represents a page\n",
    "    # and each dataframe represents a column in that page\n",
    "    pages = [list(table) for table in zip_longest(*tables)]\n",
    "\n",
    "    #Iterate over lists representing pages, starting with page 2 as \n",
    "    # page one has no previous page to push rows up to\n",
    "    for page in range(1, len(pages)):\n",
    "        # Get the number of rows which have run on from the previous page\n",
    "        num_rows = runover[page]\n",
    "        # iterate through dataframes representing page columns\n",
    "        for i, col in enumerate(pages[page]):\n",
    "            if col is not None:\n",
    "                # copy the runover rows\n",
    "                rows = col.head(num_rows)\n",
    "                # append the runover rows to the dataframes representing the previous page's columns\n",
    "                pages[page - 1][i] = pages[page - 1][i].append(rows, ignore_index=True)\n",
    "                # drop the runover rows from the dataframes they had run over into\n",
    "                col.drop(rows.index, inplace=True)\n",
    "\n",
    "    # Flatten the list so that all data frames are in the \n",
    "    # correct order for concatenation\n",
    "    table_cols = [col for page in pages for col in page]\n",
    "\n",
    "    # The last two elements are None so remove them\n",
    "    del(table_cols[-2:])\n",
    "\n",
    "    # concatenate all of the column tables into a single dataframe\n",
    "    df = pd.concat(table_cols)\n",
    "    # Set column names\n",
    "    df.columns = ['Course Code', 'Course Name', 'EOS', 'Mid']\n",
    "    # reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Remove all rows up to the header row which contain no data\n",
    "    df.drop(df.index[0:header_row], inplace=True)\n",
    "\n",
    "    # Remove rows where all values are NaN\n",
    "    df.drop(df.index[pd.isnull(df).all(1)], inplace=True)\n",
    "\n",
    "    # Rows in which Course Code is NaN and Course Name is not all caps, \n",
    "    # non-alphanumeric characters, and the words of, the, and and \n",
    "    # do not contain usable data\n",
    "    df.drop(df[~(df['Course Name'].str.contains(\n",
    "        '^[A-Z\\s\\Woftheand]+$', na=False)) & df['Course Code'].isna()], axis=1).index\n",
    "\n",
    "    # Create a new column in the dataframe for institution name \n",
    "    # identify institution name rows as those containing null course codes\n",
    "    # and add those institution names to the new institution column\n",
    "    df['Institution'] = df[df['Course Code'].isnull() | df['Course Code'].str.contains('Code')]['Course Name']\n",
    "\n",
    "    # Some Institution rows have the word 'Code' in the Course Code column (in 2006 pdfs)\n",
    "    \n",
    "\n",
    "    # Fill empty fields in the institution column with the most recent non-na field\n",
    "    df['Institution'] = df['Institution'].fillna(method='ffill')\n",
    "\n",
    "    # Remove rows containing only institution names\n",
    "    df = df[df['Course Code'].notna()]\n",
    "\n",
    "    # add remaining columns and clean up\n",
    "    df = tidy_cols(df)\n",
    "\n",
    "    # reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Search in course code column reveals some bad rows\n",
    "    # Drop any rows where Course Code does not follow /d/d/D/D/D pattern\n",
    "    df.drop(df[~df['Course Code'].str.contains('^\\D\\D\\d\\d\\d$', regex=True)].index, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88027343",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(data_dir, \"cao_2007_lvl8.pdf\")\n",
    "\n",
    "# distance in points of top of table from top of page, \n",
    "# height of table, and width of table\n",
    "top, height, width  = (18.875, 568, 246)\n",
    "\n",
    "# distance in points of left edge of page column from left edge of page\n",
    "col_locs = (18.375, 260.625, 509.625)\n",
    "\n",
    "# Table columns run over to next page in most cases\n",
    "# The 'runover' variable holds the number of rows in each page\n",
    "# that need to be push back up to the previous page\n",
    "runover = [0, 2, 4, 6, 7, 9, 0]\n",
    "\n",
    "df8_07 = get_cao_broadsheet(pdf_path, top=top, height=height, width=width, col_locs=col_locs, runover=runover, header_row=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59831529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_07.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9195a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(data_dir, \"cao_2007_lvl76.pdf\")\n",
    "\n",
    "# distance in points of top of table from top of page, \n",
    "# height of table, and width of table\n",
    "top, height, width  = (18.875, 568, 246)\n",
    "\n",
    "# distance in points of left edge of page column from left edge of page\n",
    "col_locs = (18.375, 260.625, 509.625)\n",
    "\n",
    "# Table columns run over to next page in most cases\n",
    "# The 'runover' variable holds the number of rows in each page\n",
    "# that need to be push back up to the previous page\n",
    "runover = [0, 2, 4, 0, 0]\n",
    "\n",
    "df76_07 = get_cao_broadsheet(pdf_path, top=top, height=height, width=width, col_locs=col_locs, runover=runover,header_row=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df76_07.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71637286",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d05040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(data_dir, \"cao_2006_lvl8.pdf\")\n",
    "top, height, width = (18.125, 556.5, 324.75)\n",
    "col_locs = (19.125, 353.625)\n",
    "runover = [0, 0, 4, 7, 7, 12, 15, 11, 20]\n",
    "header_row = 20\n",
    "\n",
    "df8_06 = get_cao_broadsheet(pdf_path=pdf_path, top=top, height=height, \n",
    "                            width=width, col_locs=col_locs, runover=runover, \n",
    "                            header_row=header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e793809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_06.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.path.join(data_dir, \"cao_2006_lvl76.pdf\")\n",
    "top, height, width = (18.125, 556.5, 324.75)\n",
    "col_locs = (19.125, 353.625)\n",
    "runover = [0, 0, 5, 7, 5, 14]\n",
    "header_row = 13\n",
    "\n",
    "df76_06 = get_cao_broadsheet(pdf_path=pdf_path, top=top, height=height, \n",
    "                            width=width, col_locs=col_locs, runover=runover, \n",
    "                            header_row=header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df76_06.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cab977",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cao_html(l8, l76, name_len=50):\n",
    "\n",
    "    # Regular expression to capture fields from lines\n",
    "    # Lines consist of 2 letters and 3 numbers, comprising the course code; some whitespace; \n",
    "    # 50 characters which start with a non-whitespace character; some more whitespace;\n",
    "    # some optional non whitespace characters comprising round 1 points; some more whitespace;\n",
    "    # and, optionally some more non-whitespace characters comprising round 2 points if present\n",
    "    re_fields = re.compile(f'^([A-Z]{{2}}[0-9]{{3}})\\s+(\\S.{{{name_len-1}}})\\s+(\\S+)?\\s+(\\S+)?')\n",
    "\n",
    "    # array to hold matched groups\n",
    "    data = []\n",
    "\n",
    "    for datafile, level in zip((l8, l76), (8, 76)):\n",
    "        # encoding=cp1252 necessary to decode some characters on page\n",
    "        with open(datafile, 'r', encoding='cp1252') as f:\n",
    "            for line in f:\n",
    "                match = re.match(re_fields, line)\n",
    "                if match:\n",
    "                    fields = list(match.groups())\n",
    "                    fields.append(level)\n",
    "                    data.append(fields)\n",
    "\n",
    "    # column names\n",
    "    columns = ['Course Code', 'Course Name', 'EOS', 'Mid', 'Level']\n",
    "    df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "    newcols = {'Test': '#', 'Not All': '\\*', 'AQA': 'AQA', 'New Comp': 'v'}\n",
    "\n",
    "    for k, v in newcols.items():\n",
    "        df[k] = df['EOS'].str.contains(v, na=False) | df['EOS'].str.contains(v, na=False)\n",
    "\n",
    "    # Remove Non-digits from Rnd1 and Rnd2 columns and convert columns to numeric values, \n",
    "    # with NaNs where values are missing (errors = 'coerce')\n",
    "    # (Because NaN is a float, the whole columns must be floats)\n",
    "    df['EOS'] = pd.to_numeric(df['EOS'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "    df['Mid'] = pd.to_numeric(df['Mid'].str.replace('[^0-9]+', '', regex=True), errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fdb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l8 = os.path.join(data_dir, 'cao_2004_lvl8.html')\n",
    "l76 = os.path.join(data_dir, 'cao_2004_lvl76.html')\n",
    "\n",
    "df =get_cao_html(l8, l76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d319f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d58e7",
   "metadata": {},
   "source": [
    "### 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfad8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l8 = os.path.join(data_dir, 'cao_2003_lvl8.html')\n",
    "l76 = os.path.join(data_dir, 'cao_2003_lvl76.html')\n",
    "\n",
    "df = get_cao_html(l8, l76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2aa4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118379f9",
   "metadata": {},
   "source": [
    "### 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "l8 = os.path.join(data_dir, 'cao_2002_lvl8.html')\n",
    "l76 = os.path.join(data_dir, 'cao_2002_lvl76.html')\n",
    "\n",
    "df = get_cao_html(l8, l76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6710223",
   "metadata": {},
   "source": [
    "### 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "l8 = os.path.join(data_dir, 'cao_2001_lvl8.html')\n",
    "l76 = os.path.join(data_dir, 'cao_2001_lvl76.html')\n",
    "\n",
    "df = get_cao_html(l8, l76, name_len=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369c7a5",
   "metadata": {},
   "source": [
    "## Analysing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070dc7a5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb21d15",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589f008",
   "metadata": {},
   "source": [
    "[1] https://www.independent.ie/life/family/learning/understanding-your-cao-course-guide-26505318.html\n",
    "\n",
    "\n",
    "https://tabula-py.readthedocs.io/en/latest/faq.html#how-to-use-area-option"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff05c7be86f22d0e747ff85fe7c240453a96afc5d2ecdb04243977de5be4b895"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
